from sklearn.model_selection import train_test_split
import numpy as np
import joblib
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import mean_absolute_error

# 1. Carregar dados
X = np.load('X_normalizado.npy')
y = np.load('y_saida.npy')

# 2. Normalizar y
scaler_y = StandardScaler()
y_normalizado = scaler_y.fit_transform(y)

# 3. Salvar o scaler para uso posterior
joblib.dump(scaler_y, 'scaler_y.pkl')
print("Scaler de y salvo como 'scaler_y.pkl'.")

# 4. Dividir os dados
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y_normalizado, test_size=0.15, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.1765, random_state=42)

# 4.5. Salvar conjuntos (opcional)
np.save('X_train.npy', X_train)
np.save('X_val.npy',   X_val)
np.save('X_test.npy',  X_test)
np.save('y_train.npy', y_train)
np.save('y_val.npy',   y_val)
np.save('y_test.npy',  y_test)
print("Conjuntos de dados salvos com sucesso.")

# --------------------------------------------------
# ‚Üí AQUI COME√áA O BLOCO DE GRID SEARCH SISTEM√ÅTICO
# --------------------------------------------------

import itertools
import pandas as pd

# Espa√ßo de busca
ativacoes   = ['linear', 'relu', 'tanh']
neurons     = [32, 64, 128, 256, 512]
num_layers  = [1, 2, 3, 4, 5]

resultados = []

# Carrega o scaler de y para reverter depois
scaler_y = joblib.load('scaler_y.pkl')

# Cria todas as combina√ß√µes
for ativacao, n_neuronios, camadas in itertools.product(ativacoes, neurons, num_layers):
    print(f"\nüîß Testando: ativa√ß√£o={ativacao}, "
          f"neur√¥nios={n_neuronios}, camadas={camadas}")

    # Monta o modelo
    modelo = Sequential()
    modelo.add(Dense(n_neuronios,
                     input_dim=X_train.shape[1],
                     activation=ativacao))
    for _ in range(camadas - 1):
        modelo.add(Dense(n_neuronios, activation=ativacao))
    modelo.add(Dense(y_train.shape[1], activation='linear'))

    modelo.compile(optimizer='adam', loss='mse', metrics=['mae'])
    es = EarlyStopping(monitor='val_loss', patience=10,
                       restore_best_weights=True)

    # Treina
    modelo.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=200,
        batch_size=32,
        callbacks=[es],
        verbose=0
    )

    # Avalia na escala normalizada
    loss, mae = modelo.evaluate(X_test, y_test, verbose=0)

    # Reverter normaliza√ß√£o para calcular MAE real
    y_pred_norm = modelo.predict(X_test)
    y_pred_real = scaler_y.inverse_transform(y_pred_norm)
    y_test_real = scaler_y.inverse_transform(y_test)
    mae_real = mean_absolute_error(y_test_real, y_pred_real)

    print(f"üìâ Test MAE (normalizado): {mae:.4f}")
    print(f"üìè MAE real (desnormalizado): {mae_real:.4f}")

    # Armazena resultados com ambos os MAEs
    resultados.append({
        'ativacao': ativacao,
        'neur√¥nios': n_neuronios,
        'camadas':   camadas,
        'mae_normalizado': mae,
        'mae_real': mae_real
    })

    # Salva se for o melhor
    if len(resultados) == 0 or mae_real < min([r['mae_real'] for r in resultados]):
        modelo.save('melhor_modelo.h5')
        print("üíæ Novo melhor modelo salvo como 'melhor_modelo.h5'")

# Converte em DataFrame e salva
df = pd.DataFrame(resultados).sort_values('mae_real')
print("\nüìä Top 10 modelos (por MAE real):")
print(df.head(10))

df.to_csv('resultados_comparativos.csv', index=False)
print("Resultados salvos em 'resultados_comparativos.csv'.")


import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Carregar resultados
df = pd.read_csv('resultados_comparativos.csv')

# Gr√°fico 1: Boxplot com todas as fun√ß√µes de ativa√ß√£o
plt.figure(figsize=(6, 4))
sns.boxplot(data=df, x='ativacao', y='mae', palette='Set2')
plt.title('Distribui√ß√£o do MAE por fun√ß√£o de ativa√ß√£o')
plt.xlabel('Fun√ß√£o de Ativa√ß√£o')
plt.ylabel('MAE')
plt.grid(True)
plt.tight_layout()
plt.show()

# Filtrar apenas para fun√ß√£o ReLU
df_relu = df[df['ativacao'] == 'relu']

# Gr√°fico 2: MAE m√©dio por quantidade de neur√¥nios (somente ReLU)
plt.figure(figsize=(6, 4))
sns.lineplot(data=df_relu.sort_values('neur√¥nios'), x='neur√¥nios', y='mae', marker='o', ci=None)
plt.title('MAE m√©dio por quantidade de neur√¥nios (ReLU)')
plt.xlabel('N√∫mero de Neur√¥nios')
plt.ylabel('MAE')
plt.grid(True)
plt.tight_layout()
plt.show()

# Gr√°fico 3: MAE m√©dio por n√∫mero de camadas (somente ReLU)
plt.figure(figsize=(6, 4))
sns.lineplot(data=df_relu.sort_values('camadas'), x='camadas', y='mae', marker='s', ci=None)
plt.title('MAE m√©dio por n√∫mero de camadas (ReLU)')
plt.xlabel('N√∫mero de Camadas')
plt.ylabel('MAE')
plt.grid(True)
plt.tight_layout()
plt.show()

# Gr√°fico 4: Heatmap (somente ReLU)
pivot_relu = df_relu.pivot_table(index='neur√¥nios', columns='camadas', values='mae', aggfunc='mean')

plt.figure(figsize=(6, 4))
sns.heatmap(pivot_relu, annot=True, fmt=".4f", cmap='viridis', cbar_kws={'label': 'MAE'})
plt.title('Heatmap do MAE m√©dio para fun√ß√£o ReLU (Neur√¥nios vs Camadas)')
plt.xlabel('N√∫mero de Camadas')
plt.ylabel('N√∫mero de Neur√¥nios')
plt.tight_layout()
plt.show()

